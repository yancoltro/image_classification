{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3M-NnttIUtbo"
   },
   "source": [
    "**Buscando nossos dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fazendo download da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQzN5Mf5T5hu"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/yancoltro/image_classification/raw/master/PetImages.zip\n",
    "!unzip -q PetImages.zip\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "loNrECcrUx4X"
   },
   "source": [
    "Listando nossas pastas e contando nossos arquivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pcwGRU4dU8Lf",
    "outputId": "dcd6f716-72fd-4d4c-f16f-add89eb68a05"
   },
   "outputs": [],
   "source": [
    "!ls PetImages\n",
    "!echo \"Quantidade de dados de gatos: $(ls -1 PetImages/Cat | wc -l)\" \n",
    "!echo \"Quantidade de dados de cães: $(ls -1 PetImages/Dog | wc -l)\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Importação de libs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Limpando nossos dados**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dc2HldNBV5tA"
   },
   "source": [
    "Removendo imagens possivelmente corrompidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "idMupK4DV9Ne",
    "outputId": "68defe86-e3d8-4084-a3c7-c652c3f2a4fa"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "num_skipped = 0\n",
    "for folder_name in (\"Cat\", \"Dog\"): # laço para percorrer nossa estrutura de pastas\n",
    "    folder_path = os.path.join(\"PetImages\", folder_name) #montando o caminho para buscar as imagens\n",
    "    for fname in os.listdir(folder_path):\n",
    "        fpath = os.path.join(folder_path, fname) #contatenando o nome do da pasta com cada nome de arquivo\n",
    "        try:\n",
    "            # imagens JPG tem a string JFIF no começo de seu cabeçalho, codificada em bytes\n",
    "            fobj = open(fpath, \"rb\")\n",
    "            is_jfif = tf.compat.as_bytes(\"JFIF\") in fobj.peek(10) # gerar os bytes da string JFIF, e verificar se encontra correspondencia entre os 10 primeiros bytes do arquivo\n",
    "        finally:\n",
    "            fobj.close() # fecha o arquivo\n",
    "\n",
    "        if not is_jfif:\n",
    "            num_skipped += 1 # incremente\n",
    "            os.remove(fpath) #deleta o arquivo corrompido\n",
    "\n",
    "print(\"Foram deletadas %d imagens da base de dados.\" % num_skipped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9qBbnmAsUrTu",
    "outputId": "47195896-d050-4977-924c-296afc24bd2e"
   },
   "outputs": [],
   "source": [
    "!echo \"Restaram $(ls -1 PetImages/Cat | wc -l) imagens de gatos.\" \n",
    "!echo \"Restaram $(ls -1 PetImages/Dog | wc -l) imagens de cães.\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definindo nossos dados de treinamento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerando um dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = (180, 180) #tamanho que irão ser redimensionadas as imagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jt1GVeFtZKhD",
    "outputId": "cc006c70-3f9a-49cf-c5ba-b85eb08ef610"
   },
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 32 #valor padrão, de qual tamanho serão os lotes\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"PetImages\", #caminho\n",
    "    validation_split=0.2, #quantidade fracionada para validação\n",
    "    subset=\"training\", # conjunto ao qual as imagens pertecerão\n",
    "    seed=1337, # embaralhamento\n",
    "    image_size=image_size, #tamanho da imagem\n",
    "    batch_size=batch_size, #tamanho do lote\n",
    ")\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"PetImages\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=1337,\n",
    "    image_size=image_size,\n",
    "    batch_size=batch_size,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bofkuvq9aZNj"
   },
   "source": [
    "Visualizando parte do nosso conjunto de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 608
    },
    "id": "cepn1zEZZtqG",
    "outputId": "cbaf3f90-f72f-40c0-ba29-1c98a3591d06"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        # title = \"Cachorro\" if int(labels[i]) == 1  else \"Gato\"\n",
    "        plt.title(int(labels[i]))\n",
    "        plt.title(title)\n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OMnLc42_eRrm"
   },
   "source": [
    "**Data Augmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HWpMypH5fVa_"
   },
   "source": [
    "Declaração da função do nosso data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FxzMKKcEePl-"
   },
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        # layers.Rescaling(1./255)\n",
    "    ]\n",
    ")\n",
    "# esse data augmentation rescaling exemplifica como o algorimto irá \"enxergar\" as imagens\n",
    "data_augmentation_rescaling = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.Rescaling(1./255)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lbDnSqmgfemY"
   },
   "source": [
    "Como isso afeta nossos dados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "id": "jDwd3Fr1fhny",
    "outputId": "6be7637b-08cb-47ec-8b78-81caf7b46b77"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "for images, _ in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        augmented_images = data_augmentation(images)\n",
    "        \n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n",
    "        plt.axis(\"off\")\n",
    "        # plt.show()\n",
    "        # augmented_images_rescaling = data_augmentation_rescaling(images)\n",
    "        # ax_rescaling = plt.subplot(3, 3, i + 1)\n",
    "        # plt.imshow(augmented_images_rescaling[0].numpy().astype(\"uint8\"))\n",
    "        # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bNTYpQysiAuZ"
   },
   "outputs": [],
   "source": [
    "train_ds = train_ds.prefetch(buffer_size=32)\n",
    "val_ds = val_ds.prefetch(buffer_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definindo nosso modelo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JDho-MwViHQv",
    "outputId": "aacaad9f-9b6f-4e58-8cc5-8e6cfd9b87b4"
   },
   "outputs": [],
   "source": [
    "def make_model(input_shape, num_classes):\n",
    "    inputs = keras.Input(shape=input_shape) # camada de entrada\n",
    "    \n",
    "    x = data_augmentation(inputs)\n",
    "\n",
    "    x = layers.Rescaling(1.0 / 255)(x) # camada para normalização da escala de pixels\n",
    "    x = layers.Conv2D(32, 3, strides=2, padding=\"same\")(x) # \n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.Conv2D(64, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    previous_block_activation = x \n",
    "\n",
    "    for size in [128, 256, 512, 728]: # Mapa de características\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x) #Convolução em profundidade\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.Activation(\"relu\")(x)\n",
    "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x) #Convolução em profundidade\n",
    "        x = layers.BatchNormalization()(x)\n",
    "\n",
    "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x) #Pooling\n",
    "\n",
    "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
    "            previous_block_activation\n",
    "        )\n",
    "        x = layers.add([x, residual]) \n",
    "        previous_block_activation = x \n",
    "\n",
    "    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Activation(\"relu\")(x)\n",
    "\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    if num_classes == 2:\n",
    "        activation = \"sigmoid\"\n",
    "        units = 1\n",
    "    else:\n",
    "        activation = \"softmax\"\n",
    "        units = num_classes # Definimos o numero de saídas\n",
    "\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(units, activation=activation)(x) # Camada densa\n",
    "    return keras.Model(inputs, outputs)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=image_size + (3,), num_classes=2)\n",
    "# keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treinamento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos treinar o modelo? Acho que isso pode levar alguns dias!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TCe2IjeaiaZb",
    "outputId": "0f38ee13-001c-4063-c175-bbef4b990cc0"
   },
   "outputs": [],
   "source": [
    "# epochs = 50\n",
    "\n",
    "# callbacks = [\n",
    "#     keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"), # salva os pesos a cada época\n",
    "# ]\n",
    "# model.compile(\n",
    "#     optimizer=keras.optimizers.Adam(1e-3), \n",
    "#     loss=\"binary_crossentropy\", #função de perca\n",
    "#     metrics=[\"accuracy\"],\n",
    "# )\n",
    "# model.fit(\n",
    "#     train_ds, epochs=epochs, callbacks=callbacks, validation_data=val_ds,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando as bibliotecas para importação e exportação dos modelos e pesos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras.models import save_model\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exportando o modelo treinado com as 500 imagens de gatos e cachorros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7QuZ3QZorBv"
   },
   "outputs": [],
   "source": [
    "# save_model(model, f'trained_model.h5') #exemplo de como se exporta um modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando o modelo e os pesos já treinados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://github.com/yancoltro/image_classification/raw/master/weigths.zip\n",
    "!unzip -q weigths.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = load_model( f'weigths/trained_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resultado da nossa Rede Neural**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = keras.preprocessing.image.load_img(\n",
    "    \"PetImages/Cat/441.jpg\", target_size=image_size\n",
    ")\n",
    "#img = keras.preprocessing.image.load_img(\n",
    "#    \"PetImages/Cat/3480.jpg\", target_size=image_size\n",
    "#)\n",
    "#img = keras.preprocessing.image.load_img(\n",
    "#    \"PetImages/Cat/1501.jpg\", target_size=image_size\n",
    "#)\n",
    "#img = keras.preprocessing.image.load_img(\n",
    "#    \"PetImages/Dog/407.jpg\", target_size=image_size\n",
    "#)\n",
    "#img = keras.preprocessing.image.load_img(\n",
    "#    \"PetImages/Dog/1085.jpg\", target_size=image_size\n",
    "#)\n",
    "img_array = keras.preprocessing.image.img_to_array(img)\n",
    "img_array = tf.expand_dims(img_array, 0) \n",
    "\n",
    "predictions = trained_model.predict(img_array)\n",
    "score = predictions[0]\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "print(\n",
    "    \"Essa imagem é %.2f porcento gato e %.2f porcento cachorro.\"\n",
    "    % (100 * (1 - score), 100 * score)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
